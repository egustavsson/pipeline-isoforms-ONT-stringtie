Building DAG of jobs...
Using shell: /usr/bin/bash
Provided cores: 200
Rules claiming more threads will be scaled down.
Job stats:
job                count    min threads    max threads
---------------  -------  -------------  -------------
all                    1              1              1
minimap_mapping        1            200            200
pychopper              1            200            200
run_stringtie          1            200            200
total                  4              1            200

Select jobs to execute...

[Mon May 12 12:40:08 2025]
rule pychopper:
    input: /home/MinaRyten/Emil/public_data/long-read/Ebbert_2023/sample_5356_PAM42933.fastq.gz
    output: /home/MinaRyten/Emil/public_data/long-read/Ebbert_2023/pipeline-isoforms-ONT-stringtie/sample_5356_PAM42933/Pychopper/sample_5356_PAM42933_full_length_reads.fq
    log: /home/MinaRyten/Emil/public_data/long-read/Ebbert_2023/pipeline-isoforms-ONT-stringtie/sample_5356_PAM42933/Pychopper/sample_5356_PAM42933_pychopped.log
    jobid: 3
    reason: Missing output files: /home/MinaRyten/Emil/public_data/long-read/Ebbert_2023/pipeline-isoforms-ONT-stringtie/sample_5356_PAM42933/Pychopper/sample_5356_PAM42933_full_length_reads.fq
    threads: 200
    resources: tmpdir=/tmp

Terminating processes on user request, this might take some time.
Complete log: ../../../../../Snakemakes/pipeline-isoforms-ONT-stringtie/.snakemake/log/2025-05-12T124006.701268.snakemake.log

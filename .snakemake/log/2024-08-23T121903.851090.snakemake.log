Building DAG of jobs...
Using shell: /usr/bin/bash
Provided cores: 150
Rules claiming more threads will be scaled down.
Job stats:
job                count    min threads    max threads
---------------  -------  -------------  -------------
all                    1              1              1
minimap_mapping        1            150            150
nanostat               1            150            150
pychopper              1            150            150
run_stringtie          1            150            150
total                  5              1            150

Select jobs to execute...

[Fri Aug 23 12:19:04 2024]
rule nanostat:
    input: /home/MinaRyten/Emil/public_data/long-read/Ebbert_2023/sample_5356_PAM42933.fastq
    output: Nanostat/stat_out.txt
    jobid: 1
    reason: Missing output files: Nanostat/stat_out.txt
    threads: 150
    resources: tmpdir=/tmp

Terminating processes on user request, this might take some time.
[Fri Aug 23 12:19:24 2024]
Error in rule nanostat:
    jobid: 1
    input: /home/MinaRyten/Emil/public_data/long-read/Ebbert_2023/sample_5356_PAM42933.fastq
    output: Nanostat/stat_out.txt
    shell:
        
        NanoStat -n Nanostat/stat_out.txt -t 150 --tsv --fastq /home/MinaRyten/Emil/public_data/long-read/Ebbert_2023/sample_5356_PAM42933.fastq
        
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)

Complete log: ../../../Snakemakes/pipeline-isoforms-ONT-stringtie/.snakemake/log/2024-08-23T121903.851090.snakemake.log
